{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark Lisi (ml2622)\n",
    "# Malaria Detection Using Convolutional Neural Networks\n",
    "\n",
    "\n",
    "By training a convolutional neural network (CNN) on images of cells - both infected with malaria and uninfected - we can accurately detect the presence of malaria using just an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our CNN\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# For file/image parsing\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading/Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must load our data! We are using the following cell image dataset from Kaggle: https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria\n",
    "\n",
    "Since this dataset separates infected and uninfected images, we can add binary labels as we load the images (0 for uninfected, 1 for infected). We will also employ a trick to get the most out of our image data; we will add some distorted copies of our images to the dataset. As well as effectively increasing the size of our dataset, this addition will give our model experience with imperfect images, and will ultimately strengthen it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "infected = os.listdir('data/cell_images/cell_images/Parasitized/') \n",
    "uninfected = os.listdir('data/cell_images/cell_images/Uninfected/')\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in infected:\n",
    "    try:\n",
    "        image = cv2.imread(\"data/cell_images/cell_images/Parasitized/\"+i)\n",
    "        image_array = Image.fromarray(image , 'RGB')    \n",
    "        resize_img = image_array.resize((50 , 50)) # Make sure our images are of uniform size\n",
    "        # Applying some distortions to our training data will make our model more robust!\n",
    "        rotated45 = resize_img.rotate(45)\n",
    "        rotated75 = resize_img.rotate(75)\n",
    "        blur = cv2.blur(np.array(resize_img) ,(10,10))\n",
    "        data.append(np.array(resize_img))\n",
    "        data.append(np.array(rotated45))\n",
    "        data.append(np.array(rotated75))\n",
    "        data.append(np.array(blur))\n",
    "        labels.extend([1,1,1,1])\n",
    "        \n",
    "    except AttributeError: # If CV2 can't read in the image, we discard it.\n",
    "        pass\n",
    "    \n",
    "for u in uninfected:\n",
    "    try:\n",
    "        image = cv2.imread(\"data/cell_images/cell_images/Uninfected/\"+u)\n",
    "        image_array = Image.fromarray(image , 'RGB')\n",
    "        resize_img = image_array.resize((50 , 50)) # More resizing...\n",
    "        # ...and more distortions.\n",
    "        rotated45 = resize_img.rotate(45)\n",
    "        rotated75 = resize_img.rotate(75)\n",
    "        blur = cv2.blur(np.array(resize_img) ,(10,10))\n",
    "        data.append(np.array(resize_img))\n",
    "        data.append(np.array(rotated45))\n",
    "        data.append(np.array(rotated75))\n",
    "        data.append(np.array(blur))\n",
    "        labels.extend([0,0,0,0])\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will shuffle together the infected and uninfected images and split the data into test and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(len(cells)) # n is a list of ordered indices: (0, 1, 2, ... , len(cells))\n",
    "np.random.shuffle(n) # then we shuffle it!\n",
    "\n",
    "# numpy syntax to neatly reorder a list in-place\n",
    "cells = cells[n]\n",
    "labels = labels[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(cells, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constructing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is properly loaded in, we can begin the actual classification process! Binary classification problems such as these can be approached in many ways - for image classification, convolutional neural networks are a reliably accurate option. \n",
    "\n",
    " - justify model choices, explain how things are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 50, 50, 32)        3488      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 17, 17, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 17, 17, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,537\n",
      "Trainable params: 41,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(50,50,3)),\n",
    "        layers.Conv2D(32, kernel_size=(6, 6), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(pool_size=(3, 3), padding='same'),\n",
    "        layers.Conv2D(32, kernel_size=(6, 6), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(pool_size=(3, 3), padding='same'),\n",
    "        layers.Flatten(),\n",
    "        #layers.Dropout(0.5),\n",
    "        #layers.Dense(128, activation='tanh'),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compile and start training our model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "621/621 [==============================] - 58s 94ms/step - loss: 0.8607 - accuracy: 0.6750 - val_loss: 0.4834 - val_accuracy: 0.7705\n",
      "Epoch 2/5\n",
      "621/621 [==============================] - 57s 92ms/step - loss: 0.3945 - accuracy: 0.8216 - val_loss: 0.3600 - val_accuracy: 0.8491\n",
      "Epoch 3/5\n",
      "621/621 [==============================] - 58s 94ms/step - loss: 0.2617 - accuracy: 0.8981 - val_loss: 0.2532 - val_accuracy: 0.9094\n",
      "Epoch 4/5\n",
      "621/621 [==============================] - 60s 97ms/step - loss: 0.2288 - accuracy: 0.9180 - val_loss: 0.2007 - val_accuracy: 0.9394\n",
      "Epoch 5/5\n",
      "621/621 [==============================] - 64s 104ms/step - loss: 0.1967 - accuracy: 0.9332 - val_loss: 0.1858 - val_accuracy: 0.9456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a230318dc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our CNN, we were able to achieve a training accuracy of ~94.5%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ...and Testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2048\n",
      "Test accuracy: 93.70%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Test loss: %.4f\" % score[0])\n",
    "print(\"Test accuracy: %.2f%%\" % (100*score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test accuracy is almost as high as our training accuracy - ~93.7% - which should dispel any worries of overfitting the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5a95d4dd83f25b0259fcb3ef17fcb7f292415fdb71f409246686721d1a545c8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
